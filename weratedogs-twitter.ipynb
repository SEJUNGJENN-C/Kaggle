{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport os\nimport requests\nimport time\nimport json\n#!pip install tweepy\nimport tweepy\n#!pip install wptools\nimport wptools\nfrom PIL import Image\nfrom io import BytesIO","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-10-14T16:31:04.218514Z","iopub.execute_input":"2022-10-14T16:31:04.219207Z","iopub.status.idle":"2022-10-14T16:31:26.060868Z","shell.execute_reply.started":"2022-10-14T16:31:04.219139Z","shell.execute_reply":"2022-10-14T16:31:26.059771Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Requirement already satisfied: tweepy in /opt/conda/lib/python3.7/site-packages (4.10.1)\nRequirement already satisfied: oauthlib<4,>=3.2.0 in /opt/conda/lib/python3.7/site-packages (from tweepy) (3.2.0)\nRequirement already satisfied: requests<3,>=2.27.0 in /opt/conda/lib/python3.7/site-packages (from tweepy) (2.28.1)\nRequirement already satisfied: requests-oauthlib<2,>=1.2.0 in /opt/conda/lib/python3.7/site-packages (from tweepy) (1.3.1)\nRequirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.27.0->tweepy) (2.1.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.27.0->tweepy) (3.3)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.27.0->tweepy) (1.26.12)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.27.0->tweepy) (2022.6.15.2)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mRequirement already satisfied: wptools in /opt/conda/lib/python3.7/site-packages (0.4.17)\nRequirement already satisfied: lxml in /opt/conda/lib/python3.7/site-packages (from wptools) (4.9.1)\nRequirement already satisfied: pycurl in /opt/conda/lib/python3.7/site-packages (from wptools) (7.45.1)\nRequirement already satisfied: certifi in /opt/conda/lib/python3.7/site-packages (from wptools) (2022.6.15.2)\nRequirement already satisfied: html2text in /opt/conda/lib/python3.7/site-packages (from wptools) (2020.1.16)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"markdown","source":"1. Directly download weratedogs twitter archive .csv file","metadata":{}},{"cell_type":"code","source":"tweets = pd.read_csv(\"../input/weratedogs-twitter-archive-enhanced/twitter-archive-enhanced.csv\")\ntweets.head(1)","metadata":{"execution":{"iopub.status.busy":"2022-10-14T16:31:26.066540Z","iopub.execute_input":"2022-10-14T16:31:26.066831Z","iopub.status.idle":"2022-10-14T16:31:26.126992Z","shell.execute_reply.started":"2022-10-14T16:31:26.066799Z","shell.execute_reply":"2022-10-14T16:31:26.125955Z"},"trusted":true},"execution_count":2,"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"             tweet_id  in_reply_to_status_id  in_reply_to_user_id  \\\n0  892420643555336193                    NaN                  NaN   \n\n                   timestamp  \\\n0  2017-08-01 16:23:56 +0000   \n\n                                              source  \\\n0  <a href=\"http://twitter.com/download/iphone\" r...   \n\n                                                text  retweeted_status_id  \\\n0  This is Phineas. He's a mystical boy. Only eve...                  NaN   \n\n   retweeted_status_user_id retweeted_status_timestamp  \\\n0                       NaN                        NaN   \n\n                                       expanded_urls  rating_numerator  \\\n0  https://twitter.com/dog_rates/status/892420643...                13   \n\n   rating_denominator     name doggo floofer pupper puppo  \n0                  10  Phineas  None    None   None  None  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>tweet_id</th>\n      <th>in_reply_to_status_id</th>\n      <th>in_reply_to_user_id</th>\n      <th>timestamp</th>\n      <th>source</th>\n      <th>text</th>\n      <th>retweeted_status_id</th>\n      <th>retweeted_status_user_id</th>\n      <th>retweeted_status_timestamp</th>\n      <th>expanded_urls</th>\n      <th>rating_numerator</th>\n      <th>rating_denominator</th>\n      <th>name</th>\n      <th>doggo</th>\n      <th>floofer</th>\n      <th>pupper</th>\n      <th>puppo</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>892420643555336193</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2017-08-01 16:23:56 +0000</td>\n      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n      <td>This is Phineas. He's a mystical boy. Only eve...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>https://twitter.com/dog_rates/status/892420643...</td>\n      <td>13</td>\n      <td>10</td>\n      <td>Phineas</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"2. Download the tweet image prediction .tsv file using url","metadata":{}},{"cell_type":"code","source":"folder = 'tweet_tsv'\nurl = 'https://d17h27t6h515a5.cloudfront.net/topher/2017/August/599fd2ad_image-predictions/image-predictions.tsv'\n\nif not os.path.exists(folder):\n    os.makedirs(folder)\n    \nr = requests.get(url)\nwith open(os.path.join(folder, url.split(\"/\")[-1]), mode='wb') as file:\n    response = file.write(r.content)","metadata":{"execution":{"iopub.status.busy":"2022-10-14T16:31:26.128516Z","iopub.execute_input":"2022-10-14T16:31:26.128977Z","iopub.status.idle":"2022-10-14T16:31:27.119946Z","shell.execute_reply.started":"2022-10-14T16:31:26.128934Z","shell.execute_reply":"2022-10-14T16:31:27.118710Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"image = pd.read_csv('./tweet_tsv/image-predictions.tsv', sep='\\t')\nimage.head(1)","metadata":{"execution":{"iopub.status.busy":"2022-10-14T16:31:27.123163Z","iopub.execute_input":"2022-10-14T16:31:27.123855Z","iopub.status.idle":"2022-10-14T16:31:27.152048Z","shell.execute_reply.started":"2022-10-14T16:31:27.123805Z","shell.execute_reply":"2022-10-14T16:31:27.150854Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"             tweet_id                                          jpg_url  \\\n0  666020888022790149  https://pbs.twimg.com/media/CT4udn0WwAA0aMy.jpg   \n\n   img_num                      p1   p1_conf  p1_dog      p2   p2_conf  \\\n0        1  Welsh_springer_spaniel  0.465074    True  collie  0.156665   \n\n   p2_dog                 p3   p3_conf  p3_dog  \n0    True  Shetland_sheepdog  0.061428    True  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>tweet_id</th>\n      <th>jpg_url</th>\n      <th>img_num</th>\n      <th>p1</th>\n      <th>p1_conf</th>\n      <th>p1_dog</th>\n      <th>p2</th>\n      <th>p2_conf</th>\n      <th>p2_dog</th>\n      <th>p3</th>\n      <th>p3_conf</th>\n      <th>p3_dog</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>666020888022790149</td>\n      <td>https://pbs.twimg.com/media/CT4udn0WwAA0aMy.jpg</td>\n      <td>1</td>\n      <td>Welsh_springer_spaniel</td>\n      <td>0.465074</td>\n      <td>True</td>\n      <td>collie</td>\n      <td>0.156665</td>\n      <td>True</td>\n      <td>Shetland_sheepdog</td>\n      <td>0.061428</td>\n      <td>True</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"3. Use tweepy library to query additional data via the Twitter API\n(tweet_json.txt):\n    * Tweepy (twitter api) allows us to mine the data of any twitter user. Using .get_status of the API class in tweepy module fetch a status(tweet)","metadata":{}},{"cell_type":"code","source":"consumer_key = 'mP9YUkyksJ3gGBcmLWWNjG1HK'\nconsumer_secret = 'O9joKKsymUtGXMg0rsUsr4uKm3J44y5nfadefJHm3sDWBget0b'\naccess_token = '1577688773621694465-rWwJYImL2LRjB37xJAHr51cxSECQ9G'\naccess_token_secret = '9Zvzb6dNMmAe8wTI9Ppzcsv7z63aRX5MgspDP9hHJOS0M' \n\nauth = tweepy.OAuthHandler(consumer_key, consumer_secret)\nauth.set_access_token(access_token, access_token_secret)\n# add `wait_on_rate_limit` parameter to automatically wait for rate limits to replenish\napi = tweepy.API(auth, parser=tweepy.parsers.JSONParser(), wait_on_rate_limit=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"start_time = time.time()\n\n# Save all JSON data of each tweet and save the queries into a 'tweet_json.txt' file \n# so that you only need to run the following long queries once.\nwith open ('tweet_json.txt', 'w') as file:\n    for tweet_id in tweets['tweet_id']:\n        try:\n            # Get status/tweet for each tweet_id\n            tweet = api.get_status(tweet_id, tweet_mode='extended')\n            # Convert into .json string using .dumps() function \n            # Also, add '\\n' as each tweet's JSON data to be written to its own line\n            file.write(json.dumps(tweet) + \"\\n\") \n        except Exception as e:\n            # if error occurs, print tweet_id and error message\n            print(\"No tweet found for {} with error message: {}\".format(str(tweet_id), str(e)))\n            \nend_time = time.time()\nprint(\"The process finished in {} seconds\".format(end_time - start_time))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Read JSON line by line and create a python dictionary\ninfo = []\n\nwith open('tweet_json.txt', 'r') as json_file:\n    for line in json_file:\n        # Parse JSON encoded/formatted string line by line\n        json_data = json.loads(line)\n        # Create a dictionary\n        info.append({'tweet_id': json_data['id'], #call the value by stating 'key'\n                    'favorites': json_data['favorite_count'],\n                     'retweets': json_data['retweet_count'],\n                     'timestamp': json_data['created_at']\n                    })\n\n# Create a dataframe\nadditional = pd.DataFrame(info, columns=['tweet_id', 'favorites', 'retweets', 'timestamp'])\nadditional.head(1)","metadata":{"execution":{"iopub.status.busy":"2022-10-14T16:31:27.153427Z","iopub.execute_input":"2022-10-14T16:31:27.153862Z","iopub.status.idle":"2022-10-14T16:31:27.316352Z","shell.execute_reply.started":"2022-10-14T16:31:27.153828Z","shell.execute_reply":"2022-10-14T16:31:27.315172Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"             tweet_id  favorites  retweets                       timestamp\n0  892420643555336193      33592      6950  Tue Aug 01 16:23:56 +0000 2017","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>tweet_id</th>\n      <th>favorites</th>\n      <th>retweets</th>\n      <th>timestamp</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>892420643555336193</td>\n      <td>33592</td>\n      <td>6950</td>\n      <td>Tue Aug 01 16:23:56 +0000 2017</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"## Cleaning Data\nIn this section, clean all of the issues documented.","metadata":{}},{"cell_type":"code","source":"# Before any cleaning, make a copy of original datasets.\ntweets_clean = tweets.copy()\nimage_clean = image.copy()\nadd_clean = additional.copy()","metadata":{"execution":{"iopub.status.busy":"2022-10-14T16:31:27.317857Z","iopub.execute_input":"2022-10-14T16:31:27.318297Z","iopub.status.idle":"2022-10-14T16:31:27.324621Z","shell.execute_reply.started":"2022-10-14T16:31:27.318263Z","shell.execute_reply":"2022-10-14T16:31:27.323503Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"##### Clean 1 (all tables)\nDefine: \n- Drop retweet cases from all tables as this project will only analyse original ratings that have image (no retweets)\n\nCode 1: merge tables","metadata":{"execution":{"iopub.status.busy":"2022-10-14T16:26:38.651787Z","iopub.execute_input":"2022-10-14T16:26:38.652174Z","iopub.status.idle":"2022-10-14T16:26:38.658308Z","shell.execute_reply.started":"2022-10-14T16:26:38.652144Z","shell.execute_reply":"2022-10-14T16:26:38.657221Z"}}},{"cell_type":"code","source":"# Merge `text` column to image and additional table on='tweet_id'.\n# To do so, first, create a separate table with identifier column `tweet_id` and `text`.\ntexts = tweets_clean[['tweet_id', 'text']]\n\n# Merge\nimage_clean = pd.merge(image_clean, texts, on='tweet_id')\nadd_clean = pd.merge(add_clean, texts, on='tweet_id')\n\n# Confirm\nimage_clean.columns, add_clean.columns","metadata":{"execution":{"iopub.status.busy":"2022-10-14T16:31:27.326380Z","iopub.execute_input":"2022-10-14T16:31:27.326836Z","iopub.status.idle":"2022-10-14T16:31:27.351432Z","shell.execute_reply.started":"2022-10-14T16:31:27.326790Z","shell.execute_reply":"2022-10-14T16:31:27.350056Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"(Index(['tweet_id', 'jpg_url', 'img_num', 'p1', 'p1_conf', 'p1_dog', 'p2',\n        'p2_conf', 'p2_dog', 'p3', 'p3_conf', 'p3_dog', 'text'],\n       dtype='object'),\n Index(['tweet_id', 'favorites', 'retweets', 'timestamp', 'text'], dtype='object'))"},"metadata":{}}]},{"cell_type":"markdown","source":"Code 2: remove retweets","metadata":{}},{"cell_type":"code","source":"# First, define a function that returns a mask of retweet entries.\ndef rt_mask(table):\n    mask = table.text.str.contains(\"RT\")\n    return mask\n\n# Drop retweet rows using the function.\ntweets_clean = tweets_clean[~rt_mask(tweets_clean)]\nimage_clean = image_clean[~rt_mask(image_clean)]\nadd_clean = add_clean[~rt_mask(add_clean)]","metadata":{"execution":{"iopub.status.busy":"2022-10-14T16:35:53.629829Z","iopub.execute_input":"2022-10-14T16:35:53.630437Z","iopub.status.idle":"2022-10-14T16:35:53.648168Z","shell.execute_reply.started":"2022-10-14T16:35:53.630395Z","shell.execute_reply":"2022-10-14T16:35:53.647192Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# Confirm if there is any RT left in tables. You should get False's.\nprint(tweets_clean[tweets_clean['text'].str.contains('RT')].sum().any()),\nprint(image_clean[image_clean['text'].str.contains('RT')].sum().any()),\nprint(add_clean[add_clean['text'].str.contains('RT')].sum().any())","metadata":{"execution":{"iopub.status.busy":"2022-10-14T16:39:20.345575Z","iopub.execute_input":"2022-10-14T16:39:20.345970Z","iopub.status.idle":"2022-10-14T16:39:20.367191Z","shell.execute_reply.started":"2022-10-14T16:39:20.345938Z","shell.execute_reply":"2022-10-14T16:39:20.366158Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"False\nFalse\nFalse\n","output_type":"stream"}]},{"cell_type":"code","source":"# Once it is confirmed, drop the redudant `text` columns from previously merged tables.\nimage_clean.drop('text', axis=1, inplace=True)\nadd_clean.drop('text', axis=1, inplace=True)\n\n# Confirm. Column `text` should not be included in a duplicated series.\nall_col = pd.Series(list(tweets_clean) + list(image_clean) + list(add_clean))\nall_col[all_col.duplicated()]","metadata":{"execution":{"iopub.status.busy":"2022-10-14T16:40:06.392736Z","iopub.execute_input":"2022-10-14T16:40:06.394035Z","iopub.status.idle":"2022-10-14T16:40:06.407301Z","shell.execute_reply.started":"2022-10-14T16:40:06.393987Z","shell.execute_reply":"2022-10-14T16:40:06.405994Z"},"trusted":true},"execution_count":18,"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"17     tweet_id\n29     tweet_id\n32    timestamp\ndtype: object"},"metadata":{}}]},{"cell_type":"markdown","source":"## 미완성이야아아\n##### Clean () \nDefine: \n- More rows than image (indicating there are tweets without pictures) \n- Other forms of Nan values(e.g. \"None\") \n\nCode 1:","metadata":{}},{"cell_type":"code","source":"# The `image_clean` table has 1986 rows while other tables have more than 2,000 rows.\n# This might indicate there are tweets without image. \n# As we only want to investigate tweets with image, align the row numbers to image_clean table.\n\n# Extract `tweet_id` from image_clean and make it into a list\nid_list = list(image_clean.tweet_id)\n# OR id_list = image_cleam.tweet_id.values.tolist()\n\n# Create a function\ndef drop_rows(table, col):\n    for a in table.col.values:\n        if a not in id_list:\n            table.drop(table.query('{0} == {1}'.format(col, a), axis=0, inplace=True))\n        else:\n            continue","metadata":{"execution":{"iopub.status.busy":"2022-10-14T16:48:11.326758Z","iopub.execute_input":"2022-10-14T16:48:11.327182Z","iopub.status.idle":"2022-10-14T16:48:11.335017Z","shell.execute_reply.started":"2022-10-14T16:48:11.327139Z","shell.execute_reply":"2022-10-14T16:48:11.333438Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"drop_rows(tweets_clean, tweet_id)","metadata":{"execution":{"iopub.status.busy":"2022-10-14T16:48:18.482163Z","iopub.execute_input":"2022-10-14T16:48:18.482561Z","iopub.status.idle":"2022-10-14T16:48:18.501323Z","shell.execute_reply.started":"2022-10-14T16:48:18.482528Z","shell.execute_reply":"2022-10-14T16:48:18.500219Z"},"trusted":true},"execution_count":29,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_1270/3098282353.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdrop_rows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtweets_clean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtweet_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'tweet_id' is not defined"],"ename":"NameError","evalue":"name 'tweet_id' is not defined","output_type":"error"}]},{"cell_type":"markdown","source":"##### Clean 2 (tweets_clean)\nDefine: \n- Join redundant columns into `stage` column with possible values of doggo, floofer, pupper, or puppo\n\nCode:","metadata":{}},{"cell_type":"markdown","source":"> By running the code below, you can see that other than empty space or actual stage, \"None\" string value is included in the column value.","metadata":{}},{"cell_type":"code","source":"print(\"doggo: {}, floofer: {}, puppo: {}, pupper:{}\"\n     .format(tweets_clean.doggo.unique(), \n            tweets_clean.floofer.unique(),\n            tweets_clean.puppo.unique(),\n            tweets_clean.pupper.unique()))","metadata":{"execution":{"iopub.status.busy":"2022-10-14T17:00:56.764114Z","iopub.execute_input":"2022-10-14T17:00:56.765178Z","iopub.status.idle":"2022-10-14T17:00:56.772728Z","shell.execute_reply.started":"2022-10-14T17:00:56.765133Z","shell.execute_reply":"2022-10-14T17:00:56.771592Z"},"trusted":true},"execution_count":30,"outputs":[{"name":"stdout","text":"doggo: ['None' 'doggo'], floofer: ['None' 'floofer'], puppo: ['None' 'puppo'], pupper:['None' 'pupper']\n","output_type":"stream"}]},{"cell_type":"code","source":"# So before joining the four columns, first replace \"None\" to empty-space \"\".\n# Then join the columns.\n# Some columns for example will be \"   floofer \", reflecting empty spaces created by joining the columns. So strip those empty spaces.\ntweets_clean['stage'] = (tweets_clean[['doggo', 'floofer', 'puppo', 'pupper']]\n                         .replace(\"None\",\"\").apply(lambda x: \" \".join(x), axis=1).str.strip())\n\n# Confirm if merge successful.\ntweets_clean.query(\"stage != ''\").head(1)","metadata":{"execution":{"iopub.status.busy":"2022-10-14T17:05:41.743517Z","iopub.execute_input":"2022-10-14T17:05:41.743923Z","iopub.status.idle":"2022-10-14T17:05:41.796565Z","shell.execute_reply.started":"2022-10-14T17:05:41.743890Z","shell.execute_reply":"2022-10-14T17:05:41.795491Z"},"trusted":true},"execution_count":35,"outputs":[{"execution_count":35,"output_type":"execute_result","data":{"text/plain":"             tweet_id  in_reply_to_status_id  in_reply_to_user_id  \\\n9  890240255349198849                    NaN                  NaN   \n\n                   timestamp  \\\n9  2017-07-26 15:59:51 +0000   \n\n                                              source  \\\n9  <a href=\"http://twitter.com/download/iphone\" r...   \n\n                                                text  retweeted_status_id  \\\n9  This is Cassie. She is a college pup. Studying...                  NaN   \n\n   retweeted_status_user_id retweeted_status_timestamp  \\\n9                       NaN                        NaN   \n\n                                       expanded_urls  rating_numerator  \\\n9  https://twitter.com/dog_rates/status/890240255...                14   \n\n   rating_denominator    name  doggo floofer pupper puppo  stage  \n9                  10  Cassie  doggo    None   None  None  doggo  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>tweet_id</th>\n      <th>in_reply_to_status_id</th>\n      <th>in_reply_to_user_id</th>\n      <th>timestamp</th>\n      <th>source</th>\n      <th>text</th>\n      <th>retweeted_status_id</th>\n      <th>retweeted_status_user_id</th>\n      <th>retweeted_status_timestamp</th>\n      <th>expanded_urls</th>\n      <th>rating_numerator</th>\n      <th>rating_denominator</th>\n      <th>name</th>\n      <th>doggo</th>\n      <th>floofer</th>\n      <th>pupper</th>\n      <th>puppo</th>\n      <th>stage</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>9</th>\n      <td>890240255349198849</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2017-07-26 15:59:51 +0000</td>\n      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n      <td>This is Cassie. She is a college pup. Studying...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>https://twitter.com/dog_rates/status/890240255...</td>\n      <td>14</td>\n      <td>10</td>\n      <td>Cassie</td>\n      <td>doggo</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>doggo</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# Drop the redundant columns\ntweets_clean.drop(columns = ['doggo', 'floofer', 'pupper', 'puppo'], inplace=True)\n\n# Confirm\ntweets_clean.dtypes","metadata":{"execution":{"iopub.status.busy":"2022-10-14T17:06:36.005179Z","iopub.execute_input":"2022-10-14T17:06:36.005571Z","iopub.status.idle":"2022-10-14T17:06:36.015600Z","shell.execute_reply.started":"2022-10-14T17:06:36.005539Z","shell.execute_reply":"2022-10-14T17:06:36.014697Z"},"trusted":true},"execution_count":36,"outputs":[{"execution_count":36,"output_type":"execute_result","data":{"text/plain":"tweet_id                        int64\nin_reply_to_status_id         float64\nin_reply_to_user_id           float64\ntimestamp                      object\nsource                         object\ntext                           object\nretweeted_status_id           float64\nretweeted_status_user_id      float64\nretweeted_status_timestamp     object\nexpanded_urls                  object\nrating_numerator                int64\nrating_denominator              int64\nname                           object\nstage                          object\ndtype: object"},"metadata":{}}]},{"cell_type":"markdown","source":"##### Clean 3 (all tables)\nDefine: \n- Convert wrong datatypes\n\nCode:","metadata":{}},{"cell_type":"code","source":"# Create a function that converts wrong datatypes with input arguments (table)\ndef change_dtypes(table):\n    for col in table.columns:\n        if col[-3:] == \"_id\":\n            table[col] = table[col].astype(str)\n        elif col[-5:] == \"stamp\":\n            table[col] = pd.to_datetime(table[col])\n        else:\n            table[col] = table[col]\n            \n# Call the function\nchange_dtypes(tweets_clean)\nchange_dtypes(image_clean)\nchange_dtypes(add_clean)","metadata":{"execution":{"iopub.status.busy":"2022-10-14T17:11:06.098355Z","iopub.execute_input":"2022-10-14T17:11:06.098752Z","iopub.status.idle":"2022-10-14T17:11:06.536015Z","shell.execute_reply.started":"2022-10-14T17:11:06.098719Z","shell.execute_reply":"2022-10-14T17:11:06.534862Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"# Confirm\ntweets_clean.dtypes, image_clean.dtypes, add_clean.dtypes","metadata":{"execution":{"iopub.status.busy":"2022-10-14T17:11:24.856588Z","iopub.execute_input":"2022-10-14T17:11:24.856997Z","iopub.status.idle":"2022-10-14T17:11:24.868186Z","shell.execute_reply.started":"2022-10-14T17:11:24.856963Z","shell.execute_reply":"2022-10-14T17:11:24.866668Z"},"trusted":true},"execution_count":38,"outputs":[{"execution_count":38,"output_type":"execute_result","data":{"text/plain":"(tweet_id                                   object\n in_reply_to_status_id                      object\n in_reply_to_user_id                        object\n timestamp                     datetime64[ns, UTC]\n source                                     object\n text                                       object\n retweeted_status_id                        object\n retweeted_status_user_id                   object\n retweeted_status_timestamp         datetime64[ns]\n expanded_urls                              object\n rating_numerator                            int64\n rating_denominator                          int64\n name                                       object\n stage                                      object\n dtype: object,\n tweet_id     object\n jpg_url      object\n img_num       int64\n p1           object\n p1_conf     float64\n p1_dog         bool\n p2           object\n p2_conf     float64\n p2_dog         bool\n p3           object\n p3_conf     float64\n p3_dog         bool\n dtype: object,\n tweet_id                  object\n favorites                  int64\n retweets                   int64\n timestamp    datetime64[ns, UTC]\n dtype: object)"},"metadata":{}}]},{"cell_type":"markdown","source":"##### Clean 4 (tweets_clean)\nDefine: \n- Split the table into two separate tables since the tweets_clean table contains two different units of information\n\nCode:","metadata":{"execution":{"iopub.status.busy":"2022-10-14T17:12:20.727152Z","iopub.execute_input":"2022-10-14T17:12:20.728309Z","iopub.status.idle":"2022-10-14T17:12:20.735810Z","shell.execute_reply.started":"2022-10-14T17:12:20.728264Z","shell.execute_reply":"2022-10-14T17:12:20.734319Z"}}},{"cell_type":"code","source":"tweets_clean.columns","metadata":{"execution":{"iopub.status.busy":"2022-10-14T17:12:56.150966Z","iopub.execute_input":"2022-10-14T17:12:56.151536Z","iopub.status.idle":"2022-10-14T17:12:56.161232Z","shell.execute_reply.started":"2022-10-14T17:12:56.151476Z","shell.execute_reply":"2022-10-14T17:12:56.159967Z"},"trusted":true},"execution_count":40,"outputs":[{"execution_count":40,"output_type":"execute_result","data":{"text/plain":"Index(['tweet_id', 'in_reply_to_status_id', 'in_reply_to_user_id', 'timestamp',\n       'source', 'text', 'retweeted_status_id', 'retweeted_status_user_id',\n       'retweeted_status_timestamp', 'expanded_urls', 'rating_numerator',\n       'rating_denominator', 'name', 'stage'],\n      dtype='object')"},"metadata":{}}]},{"cell_type":"code","source":"# Create a new dataframe\nratings_col = ['tweet_id', 'rating_numerator', 'rating_denominator', 'name', 'stage']\nratings = tweets_clean[ratings_col]\n\n# Drop redundant columns except for `tweet_id`\ntweets_clean.drop(columns = ratings_col[1:], inplace=True)","metadata":{"execution":{"iopub.status.busy":"2022-10-14T17:15:35.330278Z","iopub.execute_input":"2022-10-14T17:15:35.330686Z","iopub.status.idle":"2022-10-14T17:15:35.339609Z","shell.execute_reply.started":"2022-10-14T17:15:35.330654Z","shell.execute_reply":"2022-10-14T17:15:35.338402Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"# Confirm\ntweets_clean.columns","metadata":{"execution":{"iopub.status.busy":"2022-10-14T17:15:58.557417Z","iopub.execute_input":"2022-10-14T17:15:58.557808Z","iopub.status.idle":"2022-10-14T17:15:58.566830Z","shell.execute_reply.started":"2022-10-14T17:15:58.557776Z","shell.execute_reply":"2022-10-14T17:15:58.565428Z"},"trusted":true},"execution_count":42,"outputs":[{"execution_count":42,"output_type":"execute_result","data":{"text/plain":"Index(['tweet_id', 'in_reply_to_status_id', 'in_reply_to_user_id', 'timestamp',\n       'source', 'text', 'retweeted_status_id', 'retweeted_status_user_id',\n       'retweeted_status_timestamp', 'expanded_urls'],\n      dtype='object')"},"metadata":{}}]},{"cell_type":"markdown","source":"##### Clean 5 (image_clean)\nDefine: \n- Create an new column for actual breed of a dog, not falsely predicted breed.\n\nCode:\n- np.where(condition, value if condition True, value if condition False)\n- Since the prediction p1, p2, p3 is hierarchical, if the first prediction is True (i.e. is a dog), that is the prediction you want. If False (i.e. not a dog), move onto the second prediction\n- `px_dog` is vectorised, so you can just use the column itself as a condition in np.where() ","metadata":{}},{"cell_type":"code","source":"image_clean['dog_breed'] = np.where(image_clean['p1_dog'], image_clean['p1'],\n                                   np.where(image_clean['p2_dog'], image_clean['p2'],\n                                           np.where(image_clean['p3_dog'], image_clean['p3'],\n                                           np.nan)))","metadata":{"execution":{"iopub.status.busy":"2022-10-14T17:26:33.497405Z","iopub.execute_input":"2022-10-14T17:26:33.497838Z","iopub.status.idle":"2022-10-14T17:26:33.504437Z","shell.execute_reply.started":"2022-10-14T17:26:33.497803Z","shell.execute_reply":"2022-10-14T17:26:33.503228Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"code","source":"# Confirm\nimage_clean.sample(3)","metadata":{"execution":{"iopub.status.busy":"2022-10-14T17:26:35.308145Z","iopub.execute_input":"2022-10-14T17:26:35.308555Z","iopub.status.idle":"2022-10-14T17:26:35.327220Z","shell.execute_reply.started":"2022-10-14T17:26:35.308519Z","shell.execute_reply":"2022-10-14T17:26:35.326032Z"},"trusted":true},"execution_count":49,"outputs":[{"execution_count":49,"output_type":"execute_result","data":{"text/plain":"                tweet_id                                          jpg_url  \\\n738   687124485711986689  https://pbs.twimg.com/media/CYkoE10WEAAWqxm.jpg   \n17    666104133288665088  https://pbs.twimg.com/media/CT56LSZWoAAlJj2.jpg   \n1053  714214115368108032  https://pbs.twimg.com/media/Cell8ikWIAACCJ-.jpg   \n\n      img_num          p1   p1_conf  p1_dog          p2   p2_conf  p2_dog  \\\n738         1  car_mirror  0.997121   False   seat_belt  0.000375   False   \n17          1         hen  0.965932   False        cock  0.033919   False   \n1053        1         pug  0.533967    True  bloodhound  0.164826    True   \n\n                   p3   p3_conf  p3_dog dog_breed  \n738            beagle  0.000216    True    beagle  \n17          partridge  0.000052   False       NaN  \n1053  German_shepherd  0.046524    True       pug  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>tweet_id</th>\n      <th>jpg_url</th>\n      <th>img_num</th>\n      <th>p1</th>\n      <th>p1_conf</th>\n      <th>p1_dog</th>\n      <th>p2</th>\n      <th>p2_conf</th>\n      <th>p2_dog</th>\n      <th>p3</th>\n      <th>p3_conf</th>\n      <th>p3_dog</th>\n      <th>dog_breed</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>738</th>\n      <td>687124485711986689</td>\n      <td>https://pbs.twimg.com/media/CYkoE10WEAAWqxm.jpg</td>\n      <td>1</td>\n      <td>car_mirror</td>\n      <td>0.997121</td>\n      <td>False</td>\n      <td>seat_belt</td>\n      <td>0.000375</td>\n      <td>False</td>\n      <td>beagle</td>\n      <td>0.000216</td>\n      <td>True</td>\n      <td>beagle</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>666104133288665088</td>\n      <td>https://pbs.twimg.com/media/CT56LSZWoAAlJj2.jpg</td>\n      <td>1</td>\n      <td>hen</td>\n      <td>0.965932</td>\n      <td>False</td>\n      <td>cock</td>\n      <td>0.033919</td>\n      <td>False</td>\n      <td>partridge</td>\n      <td>0.000052</td>\n      <td>False</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1053</th>\n      <td>714214115368108032</td>\n      <td>https://pbs.twimg.com/media/Cell8ikWIAACCJ-.jpg</td>\n      <td>1</td>\n      <td>pug</td>\n      <td>0.533967</td>\n      <td>True</td>\n      <td>bloodhound</td>\n      <td>0.164826</td>\n      <td>True</td>\n      <td>German_shepherd</td>\n      <td>0.046524</td>\n      <td>True</td>\n      <td>pug</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"##### Clean 6 (all tables)\nDefine: \n- Drop any duplicate columns amongst tables\n\nCode:","metadata":{"execution":{"iopub.status.busy":"2022-10-14T17:26:52.263302Z","iopub.execute_input":"2022-10-14T17:26:52.263741Z","iopub.status.idle":"2022-10-14T17:26:52.270625Z","shell.execute_reply.started":"2022-10-14T17:26:52.263703Z","shell.execute_reply":"2022-10-14T17:26:52.269049Z"}}},{"cell_type":"code","source":"# Look for duplicated columns\nall_cols = pd.Series(list(tweets_clean) + list(image_clean) + list(add_clean))\nall_cols[all_cols.duplicated()]","metadata":{"execution":{"iopub.status.busy":"2022-10-14T17:28:17.587994Z","iopub.execute_input":"2022-10-14T17:28:17.588378Z","iopub.status.idle":"2022-10-14T17:28:17.598753Z","shell.execute_reply.started":"2022-10-14T17:28:17.588346Z","shell.execute_reply":"2022-10-14T17:28:17.597627Z"},"trusted":true},"execution_count":54,"outputs":[{"execution_count":54,"output_type":"execute_result","data":{"text/plain":"10     tweet_id\n23     tweet_id\n26    timestamp\ndtype: object"},"metadata":{}}]},{"cell_type":"code","source":"# Drop `timestamp` column from `add_clean` table as it is irrelevant to table's observational unit\nadd_clean.drop('timestamp', axis=1, inplace=True)\n\n# Confirm\nadd_clean.columns","metadata":{"execution":{"iopub.status.busy":"2022-10-14T17:30:57.246259Z","iopub.execute_input":"2022-10-14T17:30:57.246717Z","iopub.status.idle":"2022-10-14T17:30:57.256993Z","shell.execute_reply.started":"2022-10-14T17:30:57.246681Z","shell.execute_reply":"2022-10-14T17:30:57.255730Z"},"trusted":true},"execution_count":56,"outputs":[{"execution_count":56,"output_type":"execute_result","data":{"text/plain":"Index(['tweet_id', 'favorites', 'retweets'], dtype='object')"},"metadata":{}}]},{"cell_type":"markdown","source":"##### Clean (image_clean)\nDefine: \n- Lowercase all breed values in `p1`, `p2`, `p3` columns\n- Lowercase `dog_breed` column \n- Standardise the length of decimal numbers in `p1_conf`, `p2_conf`, `p3_conf`: .round()\n\nCode 1:","metadata":{}},{"cell_type":"code","source":"tweets_clean.to_csv('tweets_clean.csv', index=False)\nimage_clean.to_csv('image_clean.csv', index=False)\nadd_clean.to_csv('add_clean.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2022-10-14T17:34:33.343742Z","iopub.execute_input":"2022-10-14T17:34:33.344169Z","iopub.status.idle":"2022-10-14T17:34:33.406119Z","shell.execute_reply.started":"2022-10-14T17:34:33.344132Z","shell.execute_reply":"2022-10-14T17:34:33.404926Z"},"trusted":true},"execution_count":57,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}